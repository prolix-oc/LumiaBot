# Discord Bot Configuration
DISCORD_TOKEN=your_discord_bot_token_here
DISCORD_CLIENT_ID=your_discord_application_id_here
DISCORD_CLIENT_SECRET=your_discord_client_secret_here
DISCORD_REDIRECT_URI=http://localhost:3000/auth/callback

# Bot Identity Configuration (Optional)
# These values are used as template variables in prompt_storage files
# BOT_NAME=Bad Kitty                    # Bot's display name (used in {botName} template variable)
# BOT_OWNER_NAME=Prolix                 # Owner's name (used in {ownerName} template variable)
# BOT_OWNER_ID=944783522059673691       # Owner's Discord ID (used in {ownerId} template variable)
# BOT_OWNER_USERNAME=prolix_oc          # Owner's Discord username (used in {ownerUsername} template variable)

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: Custom API base URL (e.g., for OpenRouter, Together AI)
OPENAI_MODEL=gpt-4o
# OPENAI_MODEL_ALIAS=gpt-4o-mini  # Optional: Map to a different model name for the provider
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=1  # Controls randomness (0-2). Higher = more random. Default: 1
OPENAI_TOP_P=0.95  # Nucleus sampling (0-1). Default: 0.95
OPENAI_TOP_K=0  # Top-k sampling. 0 = disabled. Default: 0 (only supported by some APIs)
OPENAI_FILTER_REASONING=true  # Filter out reasoning content from responses (e.g., o1/o3 models)
# OPENAI_EXTRA_BODY={"chat_template_kwargs":{"thinking":false}}  # Optional: JSON object passed directly to API request body

# SearXNG Configuration
SEARXNG_URL=https://search.example.com
SEARXNG_MAX_RESULTS=5
SEARXNG_SAFE_SEARCH=1

# Server Configuration
PORT=3000

# Conversation History Configuration
CONVERSATION_MAX_HISTORY=20  # Maximum number of messages to keep per user (rolling window)

# Channel History Configuration
CHANNEL_MAX_HISTORY=20  # Maximum number of recent channel messages to include in context

# Google GenAI Configuration (Optional - for direct Gemini API access)
# Use this when running Gemini 3 models directly through Google's API instead of via OpenAI proxy
# GEMINI_API_KEY=your_gemini_api_key_here  # Get from https://ai.google.dev/
# GEMINI_BASE_URL=https://generativelanguage.googleapis.com  # Optional: Custom Gemini API endpoint

# Vision Secondary Model Configuration (Optional)
# Use a separate model for vision tasks when the main model doesn't support vision
# The vision model processes images/videos and feeds the description to the main model
# VISION_SECONDARY_MODEL=gpt-4o-mini                    # Model to use for vision tasks
# VISION_SECONDARY_PROVIDER=openai                      # 'openai' or 'gemini'
# VISION_SECONDARY_API_KEY=                             # Optional: different API key (defaults to main provider key)
# VISION_SECONDARY_BASE_URL=                            # Optional: different endpoint (defaults to main provider URL)
# VISION_SECONDARY_MAX_TOKENS=2000                      # Max tokens for vision model responses
# VISION_SECONDARY_TEMPERATURE=1                        # Temperature for vision model (0-2)
# VISION_SECONDARY_PROMPT_PREFIX="Describe what you see in this image in detail:"  # Prompt prefix for vision requests

# Spotify Configuration (Optional - for music playlist import)
# Get credentials from: https://developer.spotify.com/dashboard
# SPOTIFY_CLIENT_ID=your_spotify_client_id_here
# SPOTIFY_CLIENT_SECRET=your_spotify_client_secret_here

# Enable orchestrator integration (set to 'true' to enable)
# ORCHESTRATOR_ENABLED=true

# Orchestrator WebSocket URL (where the orchestrator server is running)
# ORCHESTRATOR_URL=ws://localhost:4000

# API key for authenticating with the orchestrator (must match orchestrator's API_KEY)
# ORCHESTRATOR_API_KEY=your-orchestrator-api-key

# Unique bot identifier for the orchestrator (defaults to DISCORD_CLIENT_ID)
# ORCHESTRATOR_BOT_ID=bot-unique-id

# Bot name for the orchestrator (defaults to BOT_NAME)
# ORCHESTRATOR_BOT_NAME=LumiaBot-Alpha

# Reconnection settings
# ORCHESTRATOR_RECONNECT_INTERVAL=5000
# ORCHESTRATOR_MAX_RECONNECT=10